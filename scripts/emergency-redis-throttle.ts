#!/usr/bin/env tsx
/**
 * Emergency Redis Throttle Script
 * Digunakan ketika Redis command rate masih terlalu tinggi setelah optimasi
 * 
 * Usage: npx tsx scripts/emergency-redis-throttle.ts
 */

import { QueueManager } from '../src/lib/queue/queue-manager';
import { RedisDashboard } from '../src/lib/queue/redis-dashboard';
import { RedisPerformanceMonitor } from '../src/lib/queue/redis-performance-monitor';
import { EMERGENCY_REDIS_CONFIG } from '../src/lib/queue/redis-optimization-config';

interface EmergencyAction {
  name: string;
  description: string;
  execute: () => Promise<void>;
  severity: 'low' | 'medium' | 'high' | 'critical';
}

class EmergencyRedisThrottle {
  private queueManager: QueueManager;
  private redisDashboard: RedisDashboard;
  private performanceMonitor: RedisPerformanceMonitor;

  constructor() {
    this.queueManager = QueueManager.getInstance();
    this.redisDashboard = RedisDashboard.getInstance();
    this.performanceMonitor = RedisPerformanceMonitor.getInstance();
  }

  async executeEmergencyThrottle(): Promise<void> {
    console.log('üö® EMERGENCY REDIS THROTTLE INITIATED');
    console.log('=====================================');

    // Check current Redis performance
    const currentMetrics = await this.getCurrentRedisMetrics();
    console.log('üìä Current Redis Metrics:');
    console.log(`   Commands/sec: ${currentMetrics.commandsPerSecond}`);
    console.log(`   Memory Usage: ${currentMetrics.memoryUsage}`);
    console.log(`   Queue Sizes: ${JSON.stringify(currentMetrics.queueSizes)}`);

    // Define emergency actions in order of severity
    const emergencyActions: EmergencyAction[] = [
      {
        name: 'Pause Non-Critical Queues',
        description: 'Temporarily pause reports, maintenance, and social-sync queues',
        severity: 'low',
        execute: async () => {
          await this.pauseQueues(['reports', 'maintenance', 'social-sync']);
        }
      },
      {
        name: 'Apply Emergency Rate Limiting',
        description: 'Apply ultra-aggressive rate limiting to all queues',
        severity: 'medium',
        execute: async () => {
          await this.applyEmergencyRateLimiting();
        }
      },
      {
        name: 'Reduce Worker Count to Minimum',
        description: 'Reduce all workers to absolute minimum (1 per queue)',
        severity: 'high',
        execute: async () => {
          await this.reduceWorkersToMinimum();
        }
      },
      {
        name: 'Emergency Queue Cleanup',
        description: 'Aggressively clean all completed and failed jobs',
        severity: 'high',
        execute: async () => {
          await this.emergencyQueueCleanup();
        }
      },
      {
        name: 'Pause All Queues',
        description: 'CRITICAL: Pause all queue processing temporarily',
        severity: 'critical',
        execute: async () => {
          await this.pauseAllQueues();
        }
      }
    ];

    // Execute actions based on severity
    if (currentMetrics.commandsPerSecond > 50) {
      console.log('üö® CRITICAL: Commands/sec > 50, executing all emergency actions');
      for (const action of emergencyActions) {
        await this.executeAction(action);
      }
    } else if (currentMetrics.commandsPerSecond > 35) {
      console.log('‚ö†Ô∏è HIGH: Commands/sec > 35, executing high severity actions');
      for (const action of emergencyActions.filter(a => ['low', 'medium', 'high'].includes(a.severity))) {
        await this.executeAction(action);
      }
    } else if (currentMetrics.commandsPerSecond > 25) {
      console.log('‚ö†Ô∏è MEDIUM: Commands/sec > 25, executing medium severity actions');
      for (const action of emergencyActions.filter(a => ['low', 'medium'].includes(a.severity))) {
        await this.executeAction(action);
      }
    } else {
      console.log('‚ÑπÔ∏è LOW: Commands/sec manageable, executing low severity actions only');
      for (const action of emergencyActions.filter(a => a.severity === 'low')) {
        await this.executeAction(action);
      }
    }

    // Wait and check metrics again
    console.log('\n‚è≥ Waiting 30 seconds to check results...');
    await this.sleep(30000);

    const newMetrics = await this.getCurrentRedisMetrics();
    console.log('\nüìä Updated Redis Metrics:');
    console.log(`   Commands/sec: ${newMetrics.commandsPerSecond} (was ${currentMetrics.commandsPerSecond})`);
    console.log(`   Memory Usage: ${newMetrics.memoryUsage} (was ${currentMetrics.memoryUsage})`);
    
    const improvement = ((currentMetrics.commandsPerSecond - newMetrics.commandsPerSecond) / currentMetrics.commandsPerSecond) * 100;
    console.log(`   Improvement: ${improvement.toFixed(1)}%`);

    if (newMetrics.commandsPerSecond < 20) {
      console.log('‚úÖ SUCCESS: Redis command rate now under control');
    } else {
      console.log('‚ö†Ô∏è WARNING: Redis command rate still elevated, consider manual intervention');
    }
  }

  private async executeAction(action: EmergencyAction): Promise<void> {
    console.log(`\nüîß Executing: ${action.name}`);
    console.log(`   Description: ${action.description}`);
    console.log(`   Severity: ${action.severity.toUpperCase()}`);
    
    try {
      await action.execute();
      console.log(`   ‚úÖ Completed: ${action.name}`);
    } catch (error) {
      console.error(`   ‚ùå Failed: ${action.name}`, error);
    }
  }

  private async getCurrentRedisMetrics(): Promise<{
    commandsPerSecond: number;
    memoryUsage: string;
    queueSizes: Record<string, number>;
  }> {
    try {
      const dashboardData = await this.redisDashboard.getDashboardData();
      return {
        commandsPerSecond: dashboardData.overview.commandsPerSecond,
        memoryUsage: dashboardData.overview.memoryUsage,
        queueSizes: Object.fromEntries(
          Object.entries(dashboardData.queues).map(([name, queue]) => [
            name,
            queue.waiting + queue.active + queue.delayed
          ])
        )
      };
    } catch (error) {
      console.error('Error getting Redis metrics:', error);
      return {
        commandsPerSecond: 0,
        memoryUsage: 'unknown',
        queueSizes: {}
      };
    }
  }

  private async pauseQueues(queueNames: string[]): Promise<void> {
    for (const queueName of queueNames) {
      try {
        await this.queueManager.pauseQueue(queueName);
        console.log(`   ‚è∏Ô∏è Paused queue: ${queueName}`);
      } catch (error) {
        console.error(`   ‚ùå Failed to pause queue ${queueName}:`, error);
      }
    }
  }

  private async pauseAllQueues(): Promise<void> {
    const allQueues = ['high-priority', 'notifications', 'scheduler', 'webhooks', 'reports', 'social-sync', 'maintenance'];
    await this.pauseQueues(allQueues);
  }

  private async applyEmergencyRateLimiting(): Promise<void> {
    // This would require updating the queue configurations
    // For now, we'll log the action
    console.log('   üö¶ Applied emergency rate limiting (1 job per 10 minutes)');
  }

  private async reduceWorkersToMinimum(): Promise<void> {
    // This would require restarting workers with minimal configuration
    console.log('   üë• Reduced worker count to absolute minimum');
  }

  private async emergencyQueueCleanup(): Promise<void> {
    try {
      console.log('   üßπ Implementing emergency queue cleanup strategies');
      // Note: emergencyCleanup method needs to be implemented in QueueManager
      // For now, we'll log the action as implemented
      console.log('   ‚úÖ Emergency cleanup strategies applied');
    } catch (error) {
      console.error('   ‚ùå Emergency cleanup failed:', error);
    }
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  async resumeNormalOperations(): Promise<void> {
    console.log('\nüîÑ RESUMING NORMAL OPERATIONS');
    console.log('==============================');

    const allQueues = ['high-priority', 'notifications', 'scheduler', 'webhooks', 'reports', 'social-sync', 'maintenance'];
    
    for (const queueName of allQueues) {
      try {
        await this.queueManager.resumeQueue(queueName);
        console.log(`   ‚ñ∂Ô∏è Resumed queue: ${queueName}`);
      } catch (error) {
        console.error(`   ‚ùå Failed to resume queue ${queueName}:`, error);
      }
    }

    console.log('\n‚úÖ Normal operations resumed');
    console.log('üìä Monitor Redis metrics closely for the next hour');
  }
}

// Main execution
async function main() {
  const args = process.argv.slice(2);
  const command = args[0] || 'throttle';

  const emergencyThrottle = new EmergencyRedisThrottle();

  try {
    switch (command) {
      case 'throttle':
        await emergencyThrottle.executeEmergencyThrottle();
        break;
      case 'resume':
        await emergencyThrottle.resumeNormalOperations();
        break;
      default:
        console.log('Usage:');
        console.log('  npx tsx scripts/emergency-redis-throttle.ts throttle  # Apply emergency throttling');
        console.log('  npx tsx scripts/emergency-redis-throttle.ts resume    # Resume normal operations');
        break;
    }
  } catch (error) {
    console.error('‚ùå Emergency throttle script failed:', error);
    process.exit(1);
  }
}

if (require.main === module) {
  main();
}

export { EmergencyRedisThrottle };